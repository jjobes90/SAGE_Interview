{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a3186d",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77664a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and csv file\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from numpy import mean\n",
    "\n",
    "data = pd.read_csv('Cleaned_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3940641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truck_type</th>\n",
       "      <th>value</th>\n",
       "      <th>distance</th>\n",
       "      <th>special</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reefer</td>\n",
       "      <td>2024.01</td>\n",
       "      <td>2585</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reefer</td>\n",
       "      <td>1931.33</td>\n",
       "      <td>2106</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Van</td>\n",
       "      <td>1709.99</td>\n",
       "      <td>3280</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reefer</td>\n",
       "      <td>3406.64</td>\n",
       "      <td>2082</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reefer</td>\n",
       "      <td>1189.01</td>\n",
       "      <td>2464</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Van</td>\n",
       "      <td>1468.45</td>\n",
       "      <td>2234</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Van</td>\n",
       "      <td>1355.33</td>\n",
       "      <td>3141</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Van</td>\n",
       "      <td>1649.94</td>\n",
       "      <td>1786</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Flatbed</td>\n",
       "      <td>2037.55</td>\n",
       "      <td>3375</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Reefer</td>\n",
       "      <td>1874.20</td>\n",
       "      <td>3595</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  truck_type    value  distance  special\n",
       "0     Reefer  2024.01      2585    False\n",
       "1     Reefer  1931.33      2106    False\n",
       "2        Van  1709.99      3280    False\n",
       "3     Reefer  3406.64      2082    False\n",
       "4     Reefer  1189.01      2464    False\n",
       "5        Van  1468.45      2234    False\n",
       "6        Van  1355.33      3141    False\n",
       "7        Van  1649.94      1786     True\n",
       "8    Flatbed  2037.55      3375    False\n",
       "9     Reefer  1874.20      3595    False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b6d1ea",
   "metadata": {},
   "source": [
    "# Partition Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60703e9",
   "metadata": {},
   "source": [
    "Function 1 - Baseline\n",
    "\n",
    "- Start by writing a very simple algorithm to partition the data. This will act as your baseline for comparing your next one(s). This simple algorithm does not need to satisfy every constraint well (or at all!) but should at least produce the correct number of partitions, and include some randomization.\n",
    "\n",
    "Requirements:\n",
    "1. The user can decide to use any number of partitions, from 1, up to the size of the dataset\n",
    "itself\n",
    "2. No row should ever be duplicated, modified, or left out. Each row should appear in\n",
    "exactly one partition.\n",
    "3. Each partition should have as close to the same number of rows as each other\n",
    "4. Each partition should have as close to the same number of rows from each category of\n",
    "shipment, R, V, and F\n",
    "5. The sum of the “value” column for each partition should be approximately the same\n",
    "6. The sum of the “value” column for each class (R, V, F) in each partition should be\n",
    "approximately the same.\n",
    "7. Partitions should be randomized, so that repeated partitioning tasks would not\n",
    "necessarily produce the same result each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5cf9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitionFunction1():\n",
    "    \n",
    "    # get user input\n",
    "    partitions = input(\"Enter number of partitions you would like: \")\n",
    "    random_state = input(\"Enter random state integer if you want to replicate other paritions: \")\n",
    "    \n",
    "    # re-define inputs as integers\n",
    "    random_state = int(random_state)\n",
    "    partitions = int(partitions)\n",
    "    \n",
    "    # copy data into another dataframe so function can be called multiple times without reloading page\n",
    "    iterable_data_set = data.copy()\n",
    "    \n",
    "    # define partition size and remainder to track during loop\n",
    "    partition_size = iterable_data_set.shape[0] / partitions\n",
    "    remainder = abs(partition_size - round(partition_size, 0))\n",
    "    \n",
    "    # initialize dictionary to store partitioned datasets\n",
    "    partitioned_datasets = {}\n",
    "    \n",
    "    # loop through dataset\n",
    "    for g in range(partitions):\n",
    "\n",
    "        # update running average to adjust parition sizes\n",
    "        running_average = len(iterable_data_set) / (partitions - g)\n",
    "\n",
    "        # store remaining dataset for last parition\n",
    "        if g == (partitions - 1):\n",
    "            partitioned_datasets[g] = iterable_data_set\n",
    "\n",
    "        # sample n + 1 if partition size is behind running average\n",
    "        elif (running_average > partition_size):\n",
    "            partitioned_datasets[g] = iterable_data_set.sample(n=int(partition_size + 1), random_state=random_state)\n",
    "            sample_index_list = partitioned_datasets[g].index.tolist()\n",
    "            iterable_data_set.drop(sample_index_list, axis=0, inplace=True)\n",
    "\n",
    "        # sample n if partition size is ahead of running average\n",
    "        else:\n",
    "            partitioned_datasets[g] = iterable_data_set.sample(n=int(partition_size), random_state=random_state)\n",
    "            sample_index_list = partitioned_datasets[g].index.tolist()\n",
    "            iterable_data_set.drop(sample_index_list, axis=0, inplace=True)\n",
    "            \n",
    "    # output result\n",
    "    return partitioned_datasets\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afa6803b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of partitions you would like: 11\n",
      "Enter random state integer if you want to replicate other paritions: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0:     truck_type    value  distance  special\n",
       " 507     Reefer  1448.44      1978     True\n",
       " 818        Van  1150.03       425    False\n",
       " 452    Flatbed  3517.41      1349    False\n",
       " 368        Van  2096.62      3176     True\n",
       " 242        Van  1770.94      3886    False\n",
       " ..         ...      ...       ...      ...\n",
       " 992     Reefer  1732.77      3747    False\n",
       " 463     Reefer  2045.60      3215    False\n",
       " 843     Reefer  1306.01      1858    False\n",
       " 573     Reefer  1806.70      3475    False\n",
       " 527        Van  1421.58       916    False\n",
       " \n",
       " [90 rows x 4 columns],\n",
       " 1:     truck_type    value  distance  special\n",
       " 209    Flatbed  1732.21       510    False\n",
       " 969     Reefer  2833.17       871    False\n",
       " 125        Van  1092.93      1012    False\n",
       " 286    Flatbed  1583.43       935    False\n",
       " 738        Van  1246.64      1127    False\n",
       " ..         ...      ...       ...      ...\n",
       " 66     Flatbed  1306.81      2320    False\n",
       " 667        Van  1117.90      1920    False\n",
       " 771     Reefer  1219.00       514    False\n",
       " 708    Flatbed  1397.61      1704    False\n",
       " 470    Flatbed  1714.86      2673     True\n",
       " \n",
       " [91 rows x 4 columns],\n",
       " 2:     truck_type    value  distance  special\n",
       " 109    Flatbed  1147.23       323    False\n",
       " 841     Reefer  1937.01      2963    False\n",
       " 13         Van  2077.57      3985    False\n",
       " 295     Reefer  1438.72      1615    False\n",
       " 323    Flatbed  1644.36      1154    False\n",
       " ..         ...      ...       ...      ...\n",
       " 77         Van  1124.55      1502    False\n",
       " 468     Reefer  1062.63      1694    False\n",
       " 5          Van  1468.45      2234    False\n",
       " 620     Reefer  4190.51       709    False\n",
       " 24      Reefer  1570.13      3142    False\n",
       " \n",
       " [91 rows x 4 columns],\n",
       " 3:     truck_type    value  distance  special\n",
       " 338     Reefer  1524.70       626    False\n",
       " 926        Van  1119.41      2334    False\n",
       " 219    Flatbed  1260.19       692    False\n",
       " 481     Reefer  1217.99      1123     True\n",
       " 700     Reefer  1173.93      1002    False\n",
       " ..         ...      ...       ...      ...\n",
       " 155    Flatbed  3861.79       969    False\n",
       " 304    Flatbed  1438.30      2807    False\n",
       " 846    Flatbed  1832.49      2184    False\n",
       " 513        Van  1928.59      3531    False\n",
       " 54      Reefer  1108.41      1239    False\n",
       " \n",
       " [91 rows x 4 columns],\n",
       " 4:     truck_type    value  distance  special\n",
       " 173        Van  1058.74       484    False\n",
       " 915        Van  1827.74      3670    False\n",
       " 641     Reefer  1200.35      2232    False\n",
       " 698    Flatbed  5191.86      3179    False\n",
       " 826        Van  1819.71      3636    False\n",
       " ..         ...      ...       ...      ...\n",
       " 88      Reefer  3627.52      1103    False\n",
       " 570        Van  1584.64      2422    False\n",
       " 290        Van  1285.82      1230    False\n",
       " 271        Van  1328.37      1056    False\n",
       " 456     Reefer  1717.61      2320    False\n",
       " \n",
       " [91 rows x 4 columns],\n",
       " 5:     truck_type    value  distance  special\n",
       " 367    Flatbed  3019.09      2837    False\n",
       " 180     Reefer  1255.72      1552    False\n",
       " 445        Van  1673.27      3276    False\n",
       " 845     Reefer  1618.40      2624    False\n",
       " 897    Flatbed  1573.47      1530    False\n",
       " ..         ...      ...       ...      ...\n",
       " 325     Reefer  1377.05      1481    False\n",
       " 688        Van  3467.70      1155    False\n",
       " 943    Flatbed  1684.60      3410    False\n",
       " 164     Reefer  1579.20      2146    False\n",
       " 777        Van  1341.04      2451    False\n",
       " \n",
       " [91 rows x 4 columns],\n",
       " 6:     truck_type    value  distance  special\n",
       " 166        Van  1483.32      2948    False\n",
       " 309    Flatbed  1644.00      2920    False\n",
       " 695    Flatbed  1905.38      1752    False\n",
       " 548     Reefer  1845.68      3108    False\n",
       " 473     Reefer  1151.99       348    False\n",
       " ..         ...      ...       ...      ...\n",
       " 918     Reefer  1538.30      3867    False\n",
       " 581     Reefer  1736.01      3955    False\n",
       " 839     Reefer   984.13       265    False\n",
       " 48     Flatbed  1845.13      3148    False\n",
       " 110    Flatbed  1131.94       502    False\n",
       " \n",
       " [91 rows x 4 columns],\n",
       " 7:     truck_type    value  distance  special\n",
       " 655    Flatbed  1897.66      3835    False\n",
       " 556        Van  1471.55      2019    False\n",
       " 252        Van  1388.55       982    False\n",
       " 353    Flatbed  1688.12      3416    False\n",
       " 604        Van  1032.59       432    False\n",
       " ..         ...      ...       ...      ...\n",
       " 601        Van  4893.16      1496     True\n",
       " 999     Reefer  1520.51      1895    False\n",
       " 317        Van  1121.57       298    False\n",
       " 97         Van  1559.51      2462    False\n",
       " 227     Reefer  2871.52       386    False\n",
       " \n",
       " [91 rows x 4 columns],\n",
       " 8:     truck_type    value  distance  special\n",
       " 201        Van  1948.35      3054    False\n",
       " 711     Reefer  7495.32      2136    False\n",
       " 590     Reefer  1266.95      1924    False\n",
       " 485    Flatbed  1631.10      2597    False\n",
       " 56      Reefer  1393.73      2984    False\n",
       " ..         ...      ...       ...      ...\n",
       " 73      Reefer  1321.98      1802    False\n",
       " 949    Flatbed  5621.76       777    False\n",
       " 267    Flatbed  1861.98      2396    False\n",
       " 321     Reefer  1234.75      1257    False\n",
       " 499     Reefer  1355.73      1443    False\n",
       " \n",
       " [91 rows x 4 columns],\n",
       " 9:     truck_type    value  distance  special\n",
       " 278     Reefer  1318.40      2481    False\n",
       " 458    Flatbed  5171.28      2719    False\n",
       " 544     Reefer  7975.66      2948    False\n",
       " 606     Reefer  1730.69      2167    False\n",
       " 259        Van  1761.37      3808    False\n",
       " ..         ...      ...       ...      ...\n",
       " 747        Van  1356.75      1509    False\n",
       " 51      Reefer  1367.39      2524    False\n",
       " 469        Van   647.97       615    False\n",
       " 10         Van  1249.67      1352    False\n",
       " 977     Reefer  4979.79      3340    False\n",
       " \n",
       " [91 rows x 4 columns],\n",
       " 10:     truck_type    value  distance  special\n",
       " 11         Van  3369.01       509     True\n",
       " 36         Van  3496.29      1444    False\n",
       " 52      Reefer  1367.55      2456    False\n",
       " 59         Van  1442.27      3138    False\n",
       " 63         Van  1386.58      2301    False\n",
       " ..         ...      ...       ...      ...\n",
       " 920     Reefer  1864.65      3804    False\n",
       " 924        Van  1684.52      1804    False\n",
       " 927        Van  1853.00      3815    False\n",
       " 955    Flatbed  1373.84       281    False\n",
       " 991    Flatbed  1633.07      1155    False\n",
       " \n",
       " [91 rows x 4 columns]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitionFunction1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e80b25",
   "metadata": {},
   "source": [
    "1. Describe how this algorithm works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4be952ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Algorithm Process Steps:\n",
    "\n",
    "#     1 - Load data\n",
    "\n",
    "#     2 - Get user input for partition size and randomizer value\n",
    "\n",
    "#     3 - Define partition size\n",
    "\n",
    "#     4 - Loop through dataset extracting loads from main dataset into another dictionary for analysis\n",
    "\n",
    "#         4a - Track remainder_value - ie if partition size is uneven, the remainder will grow/ shrink based on \n",
    "#              whether you round up or down when sampling \n",
    "\n",
    "#         4b - if remainder value < average parition size --> round up on sample size (ceiling)\n",
    "\n",
    "#              4b-1 - sample from dataset based on remainder value\n",
    "\n",
    "#         4c - if remainder value > average parition size --> round down on sample size (floor)\n",
    "\n",
    "#              4c-1 - sample from dataset based on remainder value\n",
    "\n",
    "#         4d - add samples to dictionary (maintaining index)\n",
    "\n",
    "#         4e - drop sample from initial dataset\n",
    "\n",
    "#         4f - on the last partition add the remaining inital dataset\n",
    "\n",
    "#      5 - END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcc13ed",
   "metadata": {},
   "source": [
    "2. What do the results look like when partitioning the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46e8215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The algorithm returns loads on n_paritions as defined\n",
    "\n",
    "# Based on the success metrics this algorithm succeeds in producing:\n",
    "#    ~ same number of loads in each partition\n",
    "#    no duplicates\n",
    "#    no loads modified\n",
    "#    randomized paritions (and seeded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8ec60",
   "metadata": {},
   "source": [
    "# Function 2 - Improving the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a89b479",
   "metadata": {},
   "source": [
    "Now write another algorithm that you think will improve the results on at least one of the\n",
    "constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35caa2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This first algorithm did not care about truck_type counts or sum of values\n",
    "\n",
    "# This second algorithm will produce more consistent value sums of each partition\n",
    "\n",
    "# To do this I will add one load at a time (vs group sampling) so the sampled load value sum \n",
    "# can be filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07cdfbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitionFunction2():\n",
    "\n",
    "    # get user input\n",
    "    partitions = input(\"Enter number of partitions you would like: \")\n",
    "    random_state = input(\"Enter random state integer if you want to replicate other paritions: \")\n",
    "\n",
    "    # re-define inputs as integers\n",
    "    random_state = int(random_state)\n",
    "    partitions = int(partitions)\n",
    "    \n",
    "    # copy data into another dataframe so function can be called multiple times without reloading page\n",
    "    iterable_data_set = data.copy()\n",
    "    \n",
    "    # define partition size and remainder to track during loop\n",
    "    partition_size = iterable_data_set.shape[0] / partitions\n",
    "    \n",
    "    # define average load value to maintain same value sum in each partition\n",
    "    avg_load_value = iterable_data_set['value'].sum() / len(iterable_data_set) \n",
    "    \n",
    "    # initialize dictionary to store partitioned datasets\n",
    "    partitioned_datasets = {}\n",
    "    \n",
    "    # define target for parition load value count\n",
    "    partition_value_sum_target = iterable_data_set['value'].sum() / partitions\n",
    "    \n",
    "    # loop through dataset\n",
    "    for g in range(partitions):\n",
    "        \n",
    "        # initialize dataframe for partition[g]\n",
    "        partitioned_datasets[g] = pd.DataFrame(columns=iterable_data_set.columns)\n",
    "        \n",
    "        # define running average target\n",
    "        running_average = len(iterable_data_set) / (partitions - g)\n",
    "        \n",
    "        # set running values to 0 before each partition\n",
    "        partition_value_sum_target_per_load = 0\n",
    "        current_partition_value_sum = 0\n",
    "        \n",
    "        # store remaining dataset for last parition\n",
    "        if g == (partitions - 1):\n",
    "            partitioned_datasets[g] = iterable_data_set\n",
    "            \n",
    "        # store partions when we do not need to increase to parition size\n",
    "        elif (running_average < partition_size):\n",
    "            \n",
    "            # store partions when we do not need to increase to parition size\n",
    "            for i in range(math.floor(partition_size)):\n",
    "                \n",
    "                # get average value count for each parition load so we can adjust accordingly\n",
    "                partition_value_sum_target_per_load = partition_value_sum_target_per_load + (partition_value_sum_target / math.floor(partition_size))\n",
    "                \n",
    "                # check if the partition value sum is lagging behind running average\n",
    "                if (i != 0 and current_partition_value_sum < partition_value_sum_target_per_load):\n",
    "                    \n",
    "                    # if so, resample so load value is larger than the average\n",
    "                    load = iterable_data_set[iterable_data_set['value'] > mean(iterable_data_set['value'])].sample(random_state=random_state)\n",
    "\n",
    "                # check if the partition value sum is ahead of running average\n",
    "                elif (i != 0 and current_partition_value_sum > partition_value_sum_target_per_load): \n",
    "\n",
    "                    # if so, resample so load value is smaller than the average\n",
    "                    load = iterable_data_set[iterable_data_set['value'] < mean(iterable_data_set['value'])].sample(random_state=random_state)\n",
    "                \n",
    "                # sample a load when i = 0\n",
    "                else:\n",
    "                    load = iterable_data_set.sample(random_state=random_state)\n",
    "\n",
    "                # add sampled load to partition\n",
    "                partitioned_datasets[g] = partitioned_datasets[g].append(load.iloc[[0]])\n",
    "\n",
    "                # drop sampled load from initial dataset\n",
    "                iterable_data_set.drop(load.index.tolist(), axis=0, inplace=True)\n",
    "                \n",
    "                # get current current parition value sum\n",
    "                current_partition_value_sum = partitioned_datasets[g]['value'].sum()\n",
    "                \n",
    "        # store partions when we do need to increase to parition size\n",
    "        else:\n",
    "            \n",
    "            # loop through initial dataset to define parition[g]\n",
    "            for i in range(math.ceil(partition_size)):\n",
    "                \n",
    "                # get average value count for each parition load so we can adjust accordingly\n",
    "                partition_value_sum_target_per_load = partition_value_sum_target_per_load + (partition_value_sum_target / math.floor(partition_size))\n",
    "                \n",
    "                # check if the partition value sum is lagging behind running average\n",
    "                if (i != 0 and current_partition_value_sum < partition_value_sum_target_per_load): \n",
    "\n",
    "                    # if so, resample so load value is larger than the average\n",
    "                    load = iterable_data_set[iterable_data_set['value'] > mean(iterable_data_set['value'])].sample(random_state=random_state)\n",
    "\n",
    "                # check if the partition value sum is ahead of running average\n",
    "                elif (i != 0 and current_partition_value_sum > partition_value_sum_target_per_load):\n",
    "\n",
    "                    # if so, resample so load value is smaller than the average\n",
    "                    load = iterable_data_set[iterable_data_set['value'] < mean(iterable_data_set['value'])].sample(random_state=random_state)\n",
    "                    \n",
    "                # sample a load when i = 0\n",
    "                else:\n",
    "                    load = iterable_data_set.sample(random_state=random_state)\n",
    "\n",
    "                # add sampled load to partition\n",
    "                partitioned_datasets[g] = partitioned_datasets[g].append(load.iloc[[0]])\n",
    "\n",
    "                # drop sampled load from initial dataset\n",
    "                iterable_data_set.drop(load.index.tolist(), axis=0, inplace=True)\n",
    "                \n",
    "                # get current current parition value sum\n",
    "                current_partition_value_sum = partitioned_datasets[g]['value'].sum()\n",
    "\n",
    "    # output result\n",
    "    return partitioned_datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e98cf",
   "metadata": {},
   "source": [
    "# Compare Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9a560e",
   "metadata": {},
   "source": [
    "- create a function to compare algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14032d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function can report the output of the algorithm (algorithm_output) or summary metrics\n",
    "\n",
    "def AlgorithmResults(function):\n",
    "    \n",
    "    # run algorithm\n",
    "    partitioned_datasets = function()\n",
    "    \n",
    "    # initilize a dataframe for test function results to be displayed\n",
    "    columns = ['Load Count', \n",
    "               'Duplicates', \n",
    "               'Sum of Values'\n",
    "              ]\n",
    "    index = range(0, len(partitioned_datasets))\n",
    "    algorithm_output = pd.DataFrame(columns=columns, index=index)\n",
    "    \n",
    "    # initialize list to store index arrays for duplication check\n",
    "    index_list = []\n",
    "\n",
    "    # loop thru partitions to extract index lists\n",
    "    for i in range(len(partitioned_datasets)):\n",
    "        \n",
    "        # get index list of each partition\n",
    "        algorithm_output.iloc[i, 0] = len(partitioned_datasets[i])\n",
    "        \n",
    "        # get duplicates in each partition\n",
    "        duplicates = [number for number in (partitioned_datasets[i].index.tolist()) if (partitioned_datasets[i].index.tolist()).count(number) > 1]\n",
    "        algorithm_output.iloc[i, 1] = len(duplicates)\n",
    "        \n",
    "        # get sum of partition value column\n",
    "        algorithm_output.iloc[i, 2] = partitioned_datasets[i]['value'].sum()\n",
    "                \n",
    "        # add index's to list\n",
    "        index_list += partitioned_datasets[i].index.tolist()\n",
    "    \n",
    "    # get duplicates of for all partitions and raise error if there are duplicates\n",
    "    duplicates_all = [number for number in index_list if index_list.count(number) > 1]\n",
    "    if sum(duplicates_all) > 1:\n",
    "        raise Exception(\"There are duplicates in some partitions!\")\n",
    "        \n",
    "    # define metrics summary table\n",
    "    metric_summary = pd.DataFrame(index=range(0,1), columns =  ['Load Count',\n",
    "                                                                 'Duplicate Count',\n",
    "                                                                 'Value Sum StDev'])\n",
    "\n",
    "    # populate metrics summary\n",
    "    metric_summary['Load Count'][0] = algorithm_output['Load Count'].sum()\n",
    "    metric_summary['Duplicate Count'][0] = round(algorithm_output['Duplicates'].sum(), 2)\n",
    "    metric_summary['Value Sum StDev'][0] = round(algorithm_output['Sum of Values'].std(), 0)\n",
    "    \n",
    "    return metric_summary\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7a698f",
   "metadata": {},
   "source": [
    "# Algorithm Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a170e7",
   "metadata": {},
   "source": [
    "Compare partition = 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41e06c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of partitions you would like: 5\n",
      "Enter random state integer if you want to replicate other paritions: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Load Count</th>\n",
       "      <th>Duplicate Count</th>\n",
       "      <th>Value Sum StDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>18184.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Load Count Duplicate Count Value Sum StDev\n",
       "0       1000               0         18184.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlgorithmResults(partitionFunction1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fcd7f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of partitions you would like: 5\n",
      "Enter random state integer if you want to replicate other paritions: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Load Count</th>\n",
       "      <th>Duplicate Count</th>\n",
       "      <th>Value Sum StDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>7363.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Load Count Duplicate Count Value Sum StDev\n",
       "0       1000               0          7363.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlgorithmResults(partitionFunction2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e821d61",
   "metadata": {},
   "source": [
    "Compare partition = 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ec12e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of partitions you would like: 10\n",
      "Enter random state integer if you want to replicate other paritions: 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Load Count</th>\n",
       "      <th>Duplicate Count</th>\n",
       "      <th>Value Sum StDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>12672.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Load Count Duplicate Count Value Sum StDev\n",
       "0       1000               0         12672.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlgorithmResults(partitionFunction1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "160e5e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of partitions you would like: 10\n",
      "Enter random state integer if you want to replicate other paritions: 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Load Count</th>\n",
       "      <th>Duplicate Count</th>\n",
       "      <th>Value Sum StDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>8037.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Load Count Duplicate Count Value Sum StDev\n",
       "0       1000               0          8037.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlgorithmResults(partitionFunction2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba16e9e",
   "metadata": {},
   "source": [
    "Compare partition = 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "491cb78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of partitions you would like: 100\n",
      "Enter random state integer if you want to replicate other paritions: 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Load Count</th>\n",
       "      <th>Duplicate Count</th>\n",
       "      <th>Value Sum StDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>4843.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Load Count Duplicate Count Value Sum StDev\n",
       "0       1000               0          4843.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlgorithmResults(partitionFunction1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c30b779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of partitions you would like: 100\n",
      "Enter random state integer if you want to replicate other paritions: 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Load Count</th>\n",
       "      <th>Duplicate Count</th>\n",
       "      <th>Value Sum StDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>4659.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Load Count Duplicate Count Value Sum StDev\n",
       "0       1000               0          4659.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlgorithmResults(partitionFunction2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51afcd26",
   "metadata": {},
   "source": [
    "# Function 2 Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc6bcf5",
   "metadata": {},
   "source": [
    "1. Describe how this algorithm works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6535c793",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Algorithm Process Steps:\n",
    "\n",
    "#     1 - Load data\n",
    "\n",
    "#     2 - Get user input for partition size and randomizer value\n",
    "\n",
    "#     3 - Define partition size\n",
    "\n",
    "#     4 - Loop through dataset extracting loads from main dataset into another dictionary for analysis\n",
    "\n",
    "#         4a - Track remainder_value - ie if partition size is uneven, the remainder will grow/ shrink based on \n",
    "#              whether you round up or down when sampling \n",
    "\n",
    "#         4b - if remainder value < average parition size --> round up on sample size (ceiling)\n",
    "\n",
    "#              4b-1 - if current partition value sum < running average --> resample for higher value\n",
    "#              4b-2 - if current partition value sum > running average --> resample for lower value\n",
    "\n",
    "#         4c - if remainder value > average parition size --> round down on sample size (floor)\n",
    "\n",
    "#              4c-1 - if current partition value sum < running average --> resample for higher value\n",
    "#              4c-2 - if current partition value sum > running average --> resample for lower value\n",
    "\n",
    "#         4d - add sample to dictionary (maintaining index)\n",
    "\n",
    "#         4e - drop sample from initial dataset\n",
    "\n",
    "#         4f - on the last partition add the remaining inital dataset\n",
    "\n",
    "#      5 - END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e4612d",
   "metadata": {},
   "source": [
    "2. Did the algorithm improve the results compared to your baseline case? How do you know?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afb30b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# based on the test function the second algorithm improved the value sum of each partition\n",
    "# see above algorithm comparisons\n",
    "\n",
    "# if a large outlier is chosen for the first partition load, the effectiveness of the algorithm\n",
    "# can be reduced\n",
    "\n",
    "# the benefit seen decreases as partition sizes increases due to the partition value sum\n",
    "# decreasing as a %\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397208b9",
   "metadata": {},
   "source": [
    "3. What can still be improved with this algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9facf3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make truck type counts and truck type value counts between partitions more equal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a63cbb6",
   "metadata": {},
   "source": [
    "# Section 3 - Final Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69695b1",
   "metadata": {},
   "source": [
    "1. What other ideas do you have for how to implement this algorithm? Describe how they might work, and why they might help improve the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec35251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# choosing the intiial load close to the mean of the dataset (vs random) would help but \n",
    "# this would reduce the random-ness of the algorithm\n",
    "\n",
    "# the same approach in algorithm 2 can be used to dial in truck type counts and their \n",
    "# respective value sums\n",
    "\n",
    "# example of optimizing truck type count:\n",
    "# when adding each load to parition -->\n",
    "#    track current_partition_truck_type_count vs running truck type count average --> \n",
    "#        then adjust sampling choice by which truck type counts are less and add them\n",
    "\n",
    "# with more time I would simplify the code (implement more functions vs procedural \n",
    "# programming) so maininting this in a production setting would be easier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3a5bcb",
   "metadata": {},
   "source": [
    "2. When might you use an algorithm like these ones in a business setting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79cc8212",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if you want to see which combination of loads produce the least or most \n",
    "# value/truck_type/special_type \n",
    "\n",
    "# ie we do not want any special loads but also want to maintain the same value sum, which \n",
    "# combination of loads produces this?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb645bb",
   "metadata": {},
   "source": [
    "3. Under what circumstances, if any, would the baseline algorithm likely be sufficient to satisfy all the constraints?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40b0250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# defining what \"close to the same number\" tolerance is for the metrics\n",
    "# if the tolerance is large enough, the first algorithm may work\n",
    "\n",
    "# if randomizing was not a requirement, the algorithm could be optimized for all metrics\n",
    "#     ie sort initial dataset and choose values based on running averages\n",
    "\n",
    "# the 'value' column outliers make randomizing while trying to keep the running averages the \n",
    "# same difficult\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
